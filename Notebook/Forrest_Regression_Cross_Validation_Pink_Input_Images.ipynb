{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pink_utils as pu\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm = pu.heatmap('../Experiment/Experiment_F3W2_95_5/F3W2_95_5_Testing_Images_EDMatrix.bin')\n",
    "images = pu.image_binary('../Experiment/Experiment_F3W2_95_5/F3W2_95_5_Testing_Images.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Experiment/Experiment_F3W2_95_5/RGZ_Test_Images_Dataframe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7464, 78)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7464, 2, 167, 167)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.file_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7464, 15, 15, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hm.file_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before time is 1538463340.5563118\n",
      "Loading the heatmaps\n",
      "Loading the cube pre-processed images\n",
      "After time is 1538463420.2692976\n",
      "\tTime difference is 79.71298575401306\n"
     ]
    }
   ],
   "source": [
    "before = time.time()\n",
    "print(f'Before time is {before}')\n",
    "print('Loading the heatmaps')\n",
    "maps = [hm.ed(index=i, prob=True) for i in range(hm.file_head[0])]\n",
    "\n",
    "# print('Loading the FIRST pre-processed images')\n",
    "# first = [images.get_image(index=i, channel=0) for i in range(hm.file_head[0])]\n",
    "\n",
    "# print('Loading the WISE pre-processed images')\n",
    "# wise = [images.get_image(index=i, channel=1) for i in range(hm.file_head[0])]\n",
    "\n",
    "print('Loading the cube pre-processed images')\n",
    "cubes = [np.concatenate([images.get_image(index=i, channel=0).flatten(), images.get_image(index=i, channel=1).flatten()]) for i in range(hm.file_head[0])]\n",
    "\n",
    "after = time.time()\n",
    "print(f'After time is {after}')\n",
    "print(f'\\tTime difference is {after-before}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "book = defaultdict(list)\n",
    "\n",
    "for c, row in df.iterrows():\n",
    "    book[row['label']].append(maps[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble.forest import RandomForestRegressor\n",
    "# from sklearn import cross_validation\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7464, 55778)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(cubes).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7464)\n",
    "index = np.random.permutation(len(maps))\n",
    "\n",
    "labels = df['label']\n",
    "num_comp  = np.array([int(i.split('_')[0]) for i in labels])[index]\n",
    "num_peaks = np.array([int(i.split('_')[1]) for i in labels])[index]\n",
    "\n",
    "# Keep heat maps to ensure nothing else breaks\n",
    "heatmaps  = np.array(cubes)[index]\n",
    "\n",
    "total = heatmaps.shape[0]\n",
    "\n",
    "suf_df = df.iloc[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before time is 1538463584.934784\n",
      "Peaks training\n"
     ]
    }
   ],
   "source": [
    "before = time.time()\n",
    "print(f'Before time is {before}')\n",
    "\n",
    "n_estimators = 64 # how many trees, should be 256\n",
    "cores = 8 # number of cpu cores to speed it up\n",
    "\n",
    "peaks_rf = RandomForestRegressor(n_estimators=n_estimators, n_jobs=cores, bootstrap=True)\n",
    "comp_rf  = RandomForestRegressor(n_estimators=n_estimators, n_jobs=cores, bootstrap=True)\n",
    "\n",
    "peaks_skf = model_selection.StratifiedKFold(n_splits=5, shuffle=False)\n",
    "comp_skf = model_selection.StratifiedKFold(n_splits=5, shuffle=False)\n",
    "\n",
    "print('Peaks training')\n",
    "peaks_res = model_selection.cross_val_predict(peaks_rf, heatmaps, num_peaks, cv=peaks_skf, n_jobs=cores)\n",
    "\n",
    "print('Comp training')\n",
    "comp_res = model_selection.cross_val_predict(comp_rf, heatmaps, num_comp, cv=comp_skf, n_jobs=cores)\n",
    "\n",
    "after = time.time()\n",
    "print(f'After time is {after}')\n",
    "print(f'\\tTime difference is {after-before}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "\n",
    "ax.scatter(comp_res, peaks_res, alpha=0.3)\n",
    "\n",
    "ax.set(xlabel='Predicted Components',\n",
    "       ylabel='Predicted Peaks')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "\n",
    "hb = ax.hexbin(comp_res, peaks_res, \n",
    "               bins='log', gridsize=20, mincnt=1)\n",
    "\n",
    "cb = fig.colorbar(hb, ax=ax)\n",
    "cb.set_label('Log(N+1)')\n",
    "\n",
    "ax.set(xlabel='Predicted Components',\n",
    "       ylabel='Predicted Peaks')\n",
    "\n",
    "# fig.show()\n",
    "fig.savefig('Images/Predicted_Features_Heatmap.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def subplot_cbar(fig, ax, im):\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax0 = divider.append_axes('right', size='5%', pad=0.05)\n",
    "        fig.colorbar(im, cax=cax0)\n",
    "    \n",
    "\n",
    "fig, axes = plt.subplots(2,3, figsize=(10, 5))\n",
    "\n",
    "for c, l in enumerate(np.sort(labels[index].unique())):\n",
    "    mask = l == labels[index]\n",
    "    \n",
    "    ax = axes.flatten()[c]\n",
    "    im = ax.hexbin(comp_res[mask], peaks_res[mask], gridsize=20, mincnt=1)\n",
    "    ax.set(title=f'{l} - N = {np.sum(mask)}', xlim=[1,3],\n",
    "          xlabel='Redicted Components',\n",
    "          ylabel='Predicted Peaks')\n",
    "    \n",
    "    subplot_cbar(fig, ax, im)\n",
    "    \n",
    "fig.tight_layout()\n",
    "fig.show()\n",
    "fig.savefig('Images/Predicted_Features_Heatmap_Classes.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize=(10,5))\n",
    "\n",
    "ax1.hist( comp_res - num_comp, bins=250 )\n",
    "ax1.set(xlabel='Predicted components - RGZ classified components',\n",
    "        ylabel='Counts')\n",
    "\n",
    "ax2.hist( peaks_res - num_peaks, bins=250 )\n",
    "ax2.set(xlabel='Predicted peaks - RGZ classified peaks',\n",
    "        ylabel='Counts')\n",
    "\n",
    "\n",
    "# fig.show()\n",
    "fig.savefig('Images/Predicted_Featurs_Histogram.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize=(10,5))\n",
    "\n",
    "val = comp_res - num_comp\n",
    "ax1.hist( val[val!=0], bins=250 )\n",
    "ax1.set(xlabel='Predicted components - RGZ classified components',\n",
    "        ylabel='Counts')\n",
    "\n",
    "val = peaks_res - num_peaks\n",
    "ax2.hist(val[val != 0], bins=250 )\n",
    "ax2.set(xlabel='Predicted peaks - RGZ classified peaks',\n",
    "        ylabel='Counts')\n",
    "\n",
    "\n",
    "# fig.show()\n",
    "fig.savefig('Images/Predicted_Featurs_Histogram_No_Zero.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_df = pd.cut(suf_df['consensus.ir_level'] , [0.6, 0.7, 0.8, 0.9, 1.0], labels=['0.6-0.7','0.7-0.8','0.8-0.9','0.9-1.0',])\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize=(8,5))\n",
    "linestyles = [':','--','-.','-']\n",
    "\n",
    "for c, b in enumerate(np.sort(bin_df.unique())):\n",
    "    print(b)\n",
    "    mask = b == bin_df\n",
    "    \n",
    "    val = comp_res - num_comp\n",
    "    ax1.hist( val[(mask)&(val!=0)], bins=50, label=f'{b}', histtype='step', linestyle=linestyles[c])\n",
    "    \n",
    "    val = peaks_res - num_peaks\n",
    "    ax2.hist(val[(mask)&(val!=0)], bins=50, label=f'{b}', histtype='step', linestyle=linestyles[c])\n",
    "\n",
    "ax1.set(xlabel='Predicted components - RGZ classified components',\n",
    "            ylabel='Counts')\n",
    "ax2.set(xlabel='Predicted peaks - RGZ classified peaks',\n",
    "        ylabel='Counts')\n",
    "\n",
    "ax1.legend(title='Radio Consensus')\n",
    "ax2.legend(title='Radio Consensus')\n",
    "fig.tight_layout()\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_df = pd.cut(suf_df['consensus.ir_level'] , [0.6, 0.7, 0.8, 0.9, 1.0], labels=['0.6-0.7','0.7-0.8','0.8-0.9','0.9-1.0',])\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize=(8,5))\n",
    "linestyles = [':','--','-.','-']\n",
    "\n",
    "for c, b in enumerate(np.sort(bin_df.unique())):\n",
    "    print(b)\n",
    "    mask = b == bin_df\n",
    "    \n",
    "    val = comp_res - num_comp\n",
    "    ax1.hist( val[mask], bins=50, label=f'{b}', histtype='step', linestyle=linestyles[c])\n",
    "    \n",
    "    val = peaks_res - num_peaks\n",
    "    ax2.hist(val[mask], bins=50, label=f'{b}', histtype='step', linestyle=linestyles[c])\n",
    "\n",
    "ax1.set(xlabel='Predicted components - RGZ classified components',\n",
    "            ylabel='Counts')\n",
    "ax2.set(xlabel='Predicted peaks - RGZ classified peaks',\n",
    "        ylabel='Counts')\n",
    "\n",
    "ax1.legend(title='Radio Consensus')\n",
    "ax2.legend(title='Radio Consensus')\n",
    "fig.tight_layout()\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize=(9,5))\n",
    "linestyles = [':','--','-.','-']\n",
    "\n",
    "val = comp_res - num_comp\n",
    "\n",
    "bin_df = pd.cut(suf_df['consensus.radio_level'] , [0.6, 0.7, 0.8, 0.9, 1.0], labels=['0.6-0.7','0.7-0.8','0.8-0.9','0.9-1.0',])\n",
    "for c, b in enumerate(np.sort(bin_df.unique())):\n",
    "    mask = b == bin_df    \n",
    "    ax1.hist( val[(mask)&(val!=0)], bins=50, label=f'{b}', histtype='step', linestyle=linestyles[c])\n",
    "\n",
    "    \n",
    "bin_df = pd.cut(suf_df['consensus.ir_level'] , [0.6, 0.7, 0.8, 0.9, 1.0], labels=['0.6-0.7','0.7-0.8','0.8-0.9','0.9-1.0',])\n",
    "for c, b in enumerate(np.sort(bin_df.unique())):\n",
    "    mask = b == bin_df    \n",
    "    ax2.hist( val[(mask)&(val!=0)], bins=50, label=f'{b}', histtype='step', linestyle=linestyles[c])\n",
    "\n",
    "ax1.set(xlabel='Predicted components - RGZ classified components',\n",
    "            ylabel='Counts')\n",
    "ax2.set(xlabel='Predicted components - RGZ classified components',\n",
    "        ylabel='Counts')\n",
    "\n",
    "ax1.legend(title='Radio Consensus')\n",
    "ax2.legend(title='IR Consensus')\n",
    "fig.tight_layout()\n",
    "# fig.show()\n",
    "fig.savefig('Images/Components_Histogram_Consensus.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize=(8,5))\n",
    "linestyles = [':','--','-.','-']\n",
    "\n",
    "val = peaks_res - num_peaks\n",
    "\n",
    "bin_df = pd.cut(suf_df['consensus.radio_level'] , [0.6, 0.7, 0.8, 0.9, 1.0], labels=['0.6-0.7','0.7-0.8','0.8-0.9','0.9-1.0',])\n",
    "for c, b in enumerate(np.sort(bin_df.unique())):\n",
    "    mask = b == bin_df    \n",
    "    ax1.hist( val[(mask)&(val!=0)], bins=50, label=f'{b}', histtype='step', linestyle=linestyles[c])\n",
    "\n",
    "    \n",
    "bin_df = pd.cut(suf_df['consensus.ir_level'] , [0.6, 0.7, 0.8, 0.9, 1.0], labels=['0.6-0.7','0.7-0.8','0.8-0.9','0.9-1.0',])\n",
    "for c, b in enumerate(np.sort(bin_df.unique())):\n",
    "    mask = b == bin_df    \n",
    "    ax2.hist( val[(mask)&(val!=0)], bins=50, label=f'{b}', histtype='step', linestyle=linestyles[c])\n",
    "\n",
    "ax1.set(xlabel='Predicted peaks - RGZ classified peaks',\n",
    "            ylabel='Counts')\n",
    "ax2.set(xlabel='Predicted peaks - RGZ classified peaks',\n",
    "        ylabel='Counts')\n",
    "\n",
    "ax1.legend(title='Radio Consensus')\n",
    "ax2.legend(title='IR Consensus')\n",
    "fig.tight_layout()\n",
    "# fig.show()\n",
    "fig.savefig('Images/Peaks_Histogram_Consensus.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize=(8,5))\n",
    "linestyles = [':','--','-.','-', '-',':']\n",
    "\n",
    "val = comp_res - num_comp\n",
    "\n",
    "bin_df = np.unique(suf_df['label'])\n",
    "for c, b in enumerate(np.sort(bin_df)):\n",
    "    mask = b ==  suf_df['label']   \n",
    "    ax1.hist( val[(mask)&(val!=0)], bins=25, label=f'{b}', histtype='step', linestyle=linestyles[c])\n",
    "\n",
    "\n",
    "val = peaks_res - num_peaks\n",
    "\n",
    "\n",
    "bin_df = np.unique(suf_df['label'])\n",
    "for c, b in enumerate(np.sort(bin_df)):\n",
    "    mask = b == suf_df['label']    \n",
    "    ax2.hist( val[(mask)&(val!=0)], bins=25, label=f'{b}', histtype='step', linestyle=linestyles[c])\n",
    "\n",
    "ax1.set(xlabel='Predicted components - RGZ classified components',\n",
    "            ylabel='Counts')\n",
    "ax2.set(xlabel='Predicted peaks - RGZ classified peaks',\n",
    "        ylabel='Counts')\n",
    "\n",
    "ax1.legend(title='RGZ Label')\n",
    "ax2.legend(title='RGZ Label')\n",
    "fig.tight_layout()\n",
    "# fig.show()\n",
    "fig.savefig('Images/RGZ_Label_Predicted_Features.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_df = np.unique(suf_df['label'])\n",
    "linestyles = [':','--','-.','-', '-',':']\n",
    "\n",
    "fig, axes = plt.subplots(len(bin_df), 2, figsize=(8, len(bin_df)*4))\n",
    "\n",
    "for count, l in enumerate(np.sort(bin_df)):\n",
    "    ax1, ax2 = axes[count]\n",
    "    \n",
    "    l_mask = l == suf_df['label']\n",
    "    val_peak = peaks_res - num_peaks\n",
    "    val_comp = comp_res - num_comp \n",
    "    \n",
    "    cen_df = pd.cut(suf_df['consensus.radio_level'] , [0.6, 0.7, 0.8, 0.9, 1.0], labels=['0.6-0.7','0.7-0.8','0.8-0.9','0.9-1.0',])\n",
    "    for c, b in enumerate(np.sort(cen_df.unique())):\n",
    "        mask = b == cen_df    \n",
    "        ax1.hist( val_peak[(mask)&(val_peak!=0)&(l_mask)], bins=50, label=f'{b}', histtype='step', linestyle=linestyles[c])\n",
    "        ax1.legend(title=f'{l} Consensus')\n",
    "        ax1.set(xlim=[-2,2], xlabel='Predicted peaks - RGZ peaks')\n",
    "        \n",
    "        ax2.hist( val_comp[(mask)&(val_comp!=0)&(l_mask)], bins=50, label=f'{b}', histtype='step', linestyle=linestyles[c])\n",
    "        ax2.legend(title=f'{l} Consensus')\n",
    "        ax2.set(xlim=[-2,2], xlabel='Predicted comp - RGZ comp')\n",
    "\n",
    "fig.tight_layout()\n",
    "# fig.show()\n",
    "fig.savefig('Images/Figure_Label_Consensus_Histogram.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_df = np.unique(suf_df['label'])\n",
    "linestyles = [':','--','-.','-', '-',':']\n",
    "\n",
    "fig, axes = plt.subplots(len(bin_df), 2, figsize=(8, len(bin_df)*4))\n",
    "\n",
    "for count, l in enumerate(np.sort(bin_df)):\n",
    "    ax1, ax2 = axes[count]\n",
    "    \n",
    "    l_mask = l == suf_df['label']\n",
    "    val_peak = peaks_res - num_peaks\n",
    "    val_comp = comp_res - num_comp \n",
    "    \n",
    "    cen_df = pd.cut(suf_df['consensus.radio_level'] , [0.6, 0.7, 0.8, 0.9, 1.0], labels=['0.6-0.7','0.7-0.8','0.8-0.9','0.9-1.0',])\n",
    "    for c, b in enumerate(np.sort(cen_df.unique())):\n",
    "        mask = b == cen_df    \n",
    "        ax1.hist( val_peak[(mask)&(l_mask)], bins=50, label=f'{b}', histtype='step', linestyle=linestyles[c])\n",
    "        ax1.legend(title=f'{l} Consensus')\n",
    "        ax1.set(xlim=[-2,2], xlabel='Predicted peaks - RGZ peaks')\n",
    "        \n",
    "        ax2.hist( val_comp[(mask)&(l_mask)], bins=50, label=f'{b}', histtype='step', linestyle=linestyles[c])\n",
    "        ax2.legend(title=f'{l} Consensus')\n",
    "        ax2.set(xlim=[-2,2], xlabel='Predicted comp - RGZ comp')\n",
    "\n",
    "fig.tight_layout()\n",
    "# fig.show()\n",
    "fig.savefig('Images/Figure_Label_Consensus_Histogram_With_Zero.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_df = np.unique(suf_df['label'])\n",
    "linestyles = [':','--','-.','-', '-',':', '--']\n",
    "\n",
    "fig, axes = plt.subplots(len(bin_df), 2, figsize=(8, len(bin_df)*4))\n",
    "\n",
    "for count, l in enumerate(np.sort(bin_df)):\n",
    "    ax1, ax2 = axes[count]\n",
    "    \n",
    "    l_mask = l == suf_df['label']\n",
    "    val_peak = peaks_res - num_peaks\n",
    "    val_comp = comp_res - num_comp \n",
    "    \n",
    "    cen_df = pd.cut(suf_df['consensus.radio_level'] , [0.6, 0.7, 0.8, 0.9, 0.95, 1.0], labels=['0.6-0.7','0.7-0.8','0.8-0.9','0.9-0.95', '0.95-1.0',])\n",
    "    for c, b in enumerate(np.sort(cen_df.unique())):\n",
    "        mask = b == cen_df    \n",
    "        ax1.hist( val_peak[(mask)&(val_peak!=0)&(l_mask)], bins=50, label=f'{b}', histtype='step', linestyle=linestyles[c])\n",
    "        ax1.legend(title=f'{l} Consensus')\n",
    "        ax1.set(xlim=[-2,2], xlabel='Predicted peaks - RGZ peaks')\n",
    "        \n",
    "        ax2.hist( val_comp[(mask)&(val_comp!=0)&(l_mask)], bins=50, label=f'{b}', histtype='step', linestyle=linestyles[c])\n",
    "        ax2.legend(title=f'{l} Consensus')\n",
    "        ax2.set(xlim=[-2,2], xlabel='Predicted comp - RGZ comp')\n",
    "\n",
    "fig.tight_layout()\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
